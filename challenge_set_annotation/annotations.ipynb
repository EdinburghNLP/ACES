{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b96d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Loading the dataset...\n",
      "INFO:logger:Dataset loaded.\n",
      "INFO:logger:Creating new stats.txt file\n",
      "INFO:logger:READY\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import numpy as np\n",
    "import json, copy, os, sys\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('logger')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n",
    "from annotation_utilities import *\n",
    "\n",
    "# this is the list of phenomena and which option they need to be annotated with:\n",
    "phenomena = {\n",
    "    'addition':'annotate_word',\n",
    "    'ambiguous-translation-wrong-discourse-connective-since-causal':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-discourse-connective-since-temporal':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-discourse-connective-while-contrast':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-discourse-connective-while-temporal':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-gender-female-anti':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-gender-female-pro':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-gender-male-anti':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-gender-male-pro':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-sense-frequent':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-sense-infrequent':'diff_flexible',\n",
    "    'anaphoric_group_it-they:deletion':'annotate_word',\n",
    "    'anaphoric_group_it-they:substitution':'annotate_word',\n",
    "    'anaphoric_intra_non-subject_it:deletion':'annotate_word',\n",
    "    'anaphoric_intra_non-subject_it:substitution':'annotate_word',\n",
    "    'anaphoric_intra_subject_it:deletion':'annotate_word',\n",
    "    'anaphoric_intra_subject_it:substitution':'annotate_word',\n",
    "    'anaphoric_intra_they:deletion':'annotate_word',\n",
    "    'anaphoric_intra_they:substitution':'annotate_word',\n",
    "    'anaphoric_singular_they:deletion':'annotate_word',\n",
    "    'anaphoric_singular_they:substitution':'annotate_word',\n",
    "    'antonym-replacement':'REF_flexible',\n",
    "    'commonsense-only-ref-ambiguous':'diff_flexible',\n",
    "    'commonsense-src-and-ref-ambiguous':'diff_flexible',\n",
    "    'copy-source':'whole_sentence',\n",
    "    'coreference-based-on-commonsense':'mixed_flexible',\n",
    "    'do-not-translate':'whole_sentence',\n",
    "    'hallucination-date-time':'date',\n",
    "    'hallucination-named-entity-level-1':'diff_flexible',\n",
    "    'hallucination-named-entity-level-2':'REF_flexible',\n",
    "    'hallucination-named-entity-level-3':'REF_flexible',\n",
    "    'hallucination-number-level-1':'diff_flexible',\n",
    "    'hallucination-number-level-2':'REF_flexible',\n",
    "    'hallucination-number-level-3':'REF_flexible',\n",
    "    'hallucination-real-data-vs-ref-word':'diff_flexible',\n",
    "    'hallucination-real-data-vs-synonym':'diff_flexible',\n",
    "    'hallucination-unit-conversion-amount-matches-ref':'units',\n",
    "    'hallucination-unit-conversion-unit-matches-ref':'units',\n",
    "    'hypernym-replacement':'REF_flexible',\n",
    "    'hyponym-replacement':'REF_flexible',\n",
    "    'lexical-overlap':'manual',\n",
    "    'modal_verb:deletion':'add-omit',\n",
    "    'modal_verb:substitution':'diff_flexible',\n",
    "    'nonsense':'REF_flexible',\n",
    "    'omission':'annotate_word',\n",
    "    'ordering-mismatch':'swap',\n",
    "    'overly-literal-vs-correct-idiom':'diff_flexible',\n",
    "    'overly-literal-vs-explanation':'diff_flexible',\n",
    "    'overly-literal-vs-ref-word':'diff_flexible',\n",
    "    'overly-literal-vs-synonym':'diff_flexible',\n",
    "    'pleonastic_it:deletion':'annotate_word',\n",
    "    'pleonastic_it:substitution':'annotate_word',\n",
    "    'punctuation:deletion_all':'add-omit',\n",
    "    'punctuation:deletion_commas':'add-omit',\n",
    "    'punctuation:deletion_quotes':'add-omit',\n",
    "    'punctuation:statement-to-question':'add-omit',\n",
    "    'real-world-knowledge-entailment':'diff_flexible',\n",
    "    'real-world-knowledge-hypernym-vs-distractor':'diff_flexible',\n",
    "    'real-world-knowledge-hypernym-vs-hyponym':'diff_flexible',\n",
    "    'real-world-knowledge-synonym-vs-antonym':'diff_flexible',\n",
    "    'similar-language-high':'whole_sentence',\n",
    "    'similar-language-low':'whole_sentence',\n",
    "    'untranslated-vs-ref-word':'diff_flexible',   # here add-omit can be used for getting character level replacements too\n",
    "    'untranslated-vs-synonym':'diff_flexible',\n",
    "    'xnli-addition-contradiction':'manual',\n",
    "    'xnli-addition-neutral':'manual',\n",
    "    'xnli-omission-contradiction':'manual',\n",
    "    'xnli-omission-neutral':'manual'\n",
    "}\n",
    "\n",
    "folder = os.getcwd()\n",
    "manual_annotations = os.path.join(folder, 'manual_annotations')\n",
    "if not os.path.exists(manual_annotations):\n",
    "    os.mkdir(manual_annotations)\n",
    "    \n",
    "phenomena_tobe_processed = input(\"enter the phenomena: \") \n",
    "if phenomena_tobe_processed == 'test':\n",
    "    # load the subset.json\n",
    "    dataset_path = os.path.join(manual_annotations, 'subset.json')\n",
    "    if not os.path.exists(dataset_path):\n",
    "        logger.error('No dataset path: %s' %(dataset_path))\n",
    "        exit()\n",
    "    logger.info('Loading the test dataset...')\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        samples = json.load(f)\n",
    "    logger.info('Test dataset loaded.')\n",
    "elif phenomena_tobe_processed == 'dataset':\n",
    "    dataset_path = os.path.join(folder, '../../dataset')\n",
    "    if not os.path.exists(dataset_path):\n",
    "        logger.error('No dataset path: %s' %(dataset_path))\n",
    "        exit()\n",
    "    logger.info('Loading the dataset...')\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    logger.info('Dataset loaded.')\n",
    "elif phenomena_tobe_processed in phenomena.keys():\n",
    "    dataset_path = os.path.join(folder, '../../dataset')\n",
    "    if not os.path.exists(dataset_path):\n",
    "        logger.error('No dataset path: %s' %(dataset_path))\n",
    "        exit()\n",
    "    logger.info('Loading the dataset...')\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    logger.info('Dataset loaded.')\n",
    "    samples = dict()\n",
    "    for idx, sample in enumerate(dataset['train']):\n",
    "        if sample['phenomena'] in phenomena_tobe_processed:\n",
    "            samples[idx] = sample        \n",
    "else:\n",
    "    logger.error(\"The phenomena should be one of these: {}\".format(sys.argv[1], phenomena.keys()))\n",
    "        \n",
    "checkpoint = os.path.join(folder, 'manual_annotations/annotated_checkpoint_{}.txt'.format(phenomena_tobe_processed))\n",
    "if os.path.exists(checkpoint):\n",
    "    logger.info('Path {} already exists. Loading..'.format(checkpoint))\n",
    "    annotations = read_json(checkpoint)\n",
    "    annotations = {int(k):v for k,v in annotations.items()}\n",
    "else:\n",
    "    annotations = dict()\n",
    "\n",
    "# calculate statistics about the annotations:\n",
    "# for every mode, calculate no. of skipped, no. of unsure and ids, and no. of done.\n",
    "stats_template = {\n",
    "            'total':0,\n",
    "            'success':0,\n",
    "            'too_long':[],\n",
    "            'no_change':[],\n",
    "            'error':[],\n",
    "            'other':[]  \n",
    "        }\n",
    "\n",
    "logger.info('Creating new stats.txt file')\n",
    "stats = {}\n",
    "for key in [phenomena_tobe_processed]:\n",
    "    stats[key] = copy.deepcopy(stats_template)\n",
    "\n",
    "res = input(\"Disable automatic accept (True to disable and anything else to not disable): \") \n",
    "automatic_accept = True\n",
    "if res.lower() == 'true':\n",
    "    automatic_accept = False\n",
    "    print('Automatic accept disabled')\n",
    "logger.info(\"READY\")\n",
    "\n",
    "def display_annotation(idx, sample):\n",
    "    m1 = \"<mark>\"\n",
    "    m2 = \"</mark>\"\n",
    "    m_len = len(m1) + len(m2)\n",
    "    n_spans = 0\n",
    "    change = sample[\"annotation\"]\n",
    "    bad_new = sample[\"incorrect-translation\"]\n",
    "    for c in change:\n",
    "        if c[\"in_bad\"] != None:\n",
    "            span = c[\"in_bad\"][\"character_span\"]\n",
    "            indices = (span[0]+n_spans*m_len, span[1]+n_spans*m_len)\n",
    "            bad_new = bad_new[:indices[0]] + m1 + bad_new[indices[0]:indices[1]] + m2 + bad_new[indices[1]:]\n",
    "            n_spans += 1\n",
    "    html = '''\n",
    "    <style>\n",
    "    mark {{\n",
    "        background-color: #4CAF50;\n",
    "        color: black;\n",
    "      }}\n",
    "    </style>\n",
    "    <body>\n",
    "    <h3>{}</h3>\n",
    "    <p>Source: {}</p>\n",
    "    <p>Reference: {}</p>\n",
    "    <p>Good translation: {}</p>\n",
    "    <p>Incorrect: {}</p>\n",
    "    <p>Phenomenon: {}</p>\n",
    "    </body>\n",
    "    '''.format(idx, sample['source'], sample['reference'], sample['good-translation'], bad_new, sample['phenomena'])\n",
    "    display(HTML(html))\n",
    "    \n",
    "def display_sample(idx, sample):\n",
    "    html = '''\n",
    "    <style>\n",
    "    mark {{\n",
    "        background-color: #4CAF50;\n",
    "        color: black;\n",
    "      }}\n",
    "    </style>\n",
    "    <body>\n",
    "    <h3>{}</h3>\n",
    "    <p>Source: {}</p>\n",
    "    <p>Reference: {}</p>\n",
    "    <p>Good translation: {}</p>\n",
    "    <p>Incorrect: {}</p>\n",
    "    <p>Phenomenon: {}</p>\n",
    "    </body>\n",
    "    '''.format(idx, sample['source'], sample['reference'], sample['good-translation'], sample['incorrect-translation'], sample['phenomena'])\n",
    "    display(HTML(html))\n",
    "    \n",
    "def display_annotation_old(idx, sample):\n",
    "    print(\"\\nID: \", idx)\n",
    "    print(\"Source sentence: \", sample['source'])\n",
    "    print(\"Reference: \", sample['reference'])\n",
    "    print(\"Good Translation: \", sample['good-translation'])\n",
    "    print(\"Incorrect Translation: \", sample['incorrect-translation'])\n",
    "    print('Suggested annotation:')\n",
    "    print(annotations[idx]['annotation'], '\\n')\n",
    "    \n",
    "# the UI (?) part of the annotation in general (ask if they want to accept the annotation, call manual_annotation if no)\n",
    "def manual_annotation_io(idx):\n",
    "    sample = samples[idx]\n",
    "    if idx in annotations:\n",
    "        change = annotations[idx]['annotation']   # now it's normalized annotation.\n",
    "        if automatic_accept and len(change) == 1 and len(change[0][\"in_good\"]['token_index']) == len(change[0][\"in_bad\"]['token_index']):\n",
    "            return 0\n",
    "    if phenomena[sample[\"phenomena\"]] in ['?', 'mixed_flexible']:\n",
    "        print(\"-----> For this sample we can compare the Incorrect translation with either Reference or Good translation.\")\n",
    "    elif phenomena[sample[\"phenomena\"]] in ['REF_flexible']:\n",
    "        print(\"-----> For this sample we compare the Incorrect translation with the Reference.\")\n",
    "    else:\n",
    "        print(\"-----> For this sample we compare the Incorrect translation with the Good translation.\\n\")\n",
    "    if idx in annotations:\n",
    "        display_annotation(idx, sample)\n",
    "        inp = input('To accept the suggested annotation click on enter. To skip this one enter skip. To exit enter exit and enter anything else to manually annotate:')\n",
    "        if inp == \"skip\":\n",
    "            annotations.pop(idx)\n",
    "            return 1  # this means, we are skipping, so should delete this annotation and then continue with the next.\n",
    "        if inp == \"exit\":\n",
    "            # do not add the annotation if you stop at this point\n",
    "            annotations.pop(idx)\n",
    "            return -1\n",
    "        res = manual_annotation(idx, inp)\n",
    "        if res == -1:\n",
    "            # do not add the annotation if you stop at this point\n",
    "            annotations.pop(idx)\n",
    "            return -1\n",
    "        if res == 1:\n",
    "            # skipping\n",
    "            annotations.pop(idx)\n",
    "            return 1\n",
    "    else:\n",
    "        display_sample(idx, sample)\n",
    "        print(\"No automatic translations for this sample.\")\n",
    "        res = manual_annotation(idx)\n",
    "        if res == -1:\n",
    "            return -1\n",
    "\n",
    "# the UI (?) part of the manual annotation\n",
    "def manual_annotation(idx, inp=\".\"):\n",
    "    while inp != \"\":\n",
    "        sample = samples[idx]\n",
    "        inp = input(\"Enter the incorrect translation with the < and > to show the error spans (exit to stop, skip to skip): \\n\")\n",
    "        bad = inp\n",
    "        if bad == \"exit\":\n",
    "            return -1\n",
    "        if bad == \"skip\":\n",
    "            return 1\n",
    "        inp = input(\"Enter the correct/reference translation with the < and > to show the error spans (exit to stop, skip to skip): \\n\")\n",
    "        good = inp\n",
    "        if good == \"exit\":\n",
    "            return -1\n",
    "        if good == \"skip\":\n",
    "            return 1\n",
    "        \n",
    "        change = calculate_change(good, bad, sample)\n",
    "        tmp = copy.deepcopy(sample)\n",
    "        tmp[\"annotation\"] = change\n",
    "        display_annotation(idx, tmp)\n",
    "        inp = input(\"\\n To accept it press enter or to annotate again enter any other string: \")\n",
    "        if inp == \"\":\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = \"manual annotation\"\n",
    "            annotations[idx] = sample\n",
    "    return annotations[idx]\n",
    "\n",
    "# given a manually annotated sample (where there are <> in incorrect and good/reference sentences)\n",
    "# calculate the character spans in the original sentences and return the change in our annotation format\n",
    "def calculate_change(good, bad, sample):  \n",
    "    bad_id = 0\n",
    "    span = False # False is when we are not inside a span, True is inside a span\n",
    "    change = []\n",
    "    for i, c in enumerate(bad):\n",
    "        if c == \"<\":\n",
    "            if span:\n",
    "                logger.error(\"< not closed. Try again.\\n\")\n",
    "                return manual_annotation(\".\", sample)\n",
    "            else:\n",
    "                start = bad_id\n",
    "                start_annotate = i\n",
    "                bad_id -= 1\n",
    "                span = True\n",
    "        elif c == \">\":\n",
    "            if not span:\n",
    "                logger.error(\"No opening < Try again.\\n\")\n",
    "                return manual_annotation(\".\", sample)\n",
    "            else:\n",
    "                change.append({\"in_good\":None, \n",
    "                    \"in_bad\":{'token_index':None, \n",
    "                    'character_span':(start,bad_id), \n",
    "                               'token':bad[start_annotate+1:i]}})\n",
    "                bad_id -= 1\n",
    "                span = False\n",
    "        bad_id += 1\n",
    "    good_id = 0\n",
    "    span = False # False is when we are not inside a span, True is inside a span\n",
    "    for i, c in enumerate(good):\n",
    "        if c == \"<\":\n",
    "            if span:\n",
    "                logger.error(\"< not closed. Try again.\\n\")\n",
    "                return manual_annotation(\".\", sample)\n",
    "            else:\n",
    "                start = good_id\n",
    "                start_annotate = i\n",
    "                good_id -= 1\n",
    "                span = True\n",
    "        elif c == \">\":\n",
    "            if not span:\n",
    "                logger.error(\"No opening < Try again.\\n\")\n",
    "                return manual_annotation(\".\", sample)\n",
    "            else:\n",
    "                change.append({\"in_good\":{'token_index':None, \n",
    "                    'character_span':(start,good_id), \n",
    "                               'token':good[start_annotate+1:i]}, \n",
    "                    \"in_bad\":None})\n",
    "                good_id -= 1\n",
    "                span = False\n",
    "        good_id += 1\n",
    "    return change\n",
    "\n",
    "# process given sample, annotate or do manual annotation (only in the annotations.ipynb, in process_dataset.py only automatic annotation)\n",
    "def process_sample(idx, sample, manual=False, detokenize=False):\n",
    "    if phenomena[sample[\"phenomena\"]] == 'mixed_flexible':\n",
    "        good_og = ref_or_good(sample[\"reference\"], sample[\"good-translation\"], sample[\"incorrect-translation\"])\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'REF_flexible':\n",
    "        good_og = sample[\"reference\"]\n",
    "    else:\n",
    "        good_og = sample[\"good-translation\"]\n",
    "    bad_og = sample[\"incorrect-translation\"]\n",
    "    # if detokenize we just annotate the detokenized sentences, then map the character span back to the original sentence\n",
    "    # in the standardize_annotation function in annotation_utilities.py\n",
    "    if detokenize:\n",
    "        try:\n",
    "            good, good_map = detokenize_text(good_og, lang=sample[\"langpair\"].split('-')[1])\n",
    "            bad, bad_map = detokenize_text(bad_og, lang=sample[\"langpair\"].split('-')[1])\n",
    "            maps = (good_map, bad_map)\n",
    "        except:\n",
    "            good, bad = good_og, bad_og\n",
    "            maps = None\n",
    "    else:\n",
    "        good, bad = good_og, bad_og\n",
    "        maps = None # the standardize_annotation function will understand that it does not need to revert detokenization \n",
    "        # if maps parameter is None.\n",
    "    originals = (good_og, bad_og)\n",
    "    \n",
    "    if phenomena[sample[\"phenomena\"]] == 'add-omit':\n",
    "        try:\n",
    "            change = diff_char_level(good, bad)\n",
    "            if len(change) == 0:\n",
    "                logger.warning('No change in id {}'.format(idx))\n",
    "            else:\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample\n",
    "        except:\n",
    "            logger.warning('error in char level annotate, id {}'.format(idx))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'annotate_word':\n",
    "        try:\n",
    "            change = annotate_word(good, bad)\n",
    "            if len(change) == 0:\n",
    "                logger.warning('No change in id {}'.format(idx))\n",
    "                stats[sample[\"phenomena\"]][\"no_change\"].append((idx, sample['langpair']))\n",
    "            elif len(change) > 5:\n",
    "                stats[sample[\"phenomena\"]][\"too_long\"].append(idx)\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            else:\n",
    "                stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample\n",
    "        except:\n",
    "            logger.warning('error in word level annotate, id {}'.format(idx))\n",
    "            stats[sample[\"phenomena\"]][\"error\"].append((idx, sample['langpair']))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] in ['diff_flexible', 'REF_flexible', 'mixed_flexible']:\n",
    "        g, g_spans = tokenize(good)\n",
    "        b, b_spans = tokenize(bad)\n",
    "\n",
    "        # special treatment to japanese chinese and thailandish because they don't use spaces, so can't be split            \n",
    "        if sample['langpair'][-2:] not in ['ja', 'zh', 'th']:      \n",
    "            if len(g) == len(b):   # if there are multiple one word replacements\n",
    "                change = diff(g, g_spans, b, b_spans, phenomena=\"replacement\")\n",
    "            if len(g) != len(b) or len(change) == 0:\n",
    "                try:\n",
    "                    change = diff_flexible(good, g, g_spans, bad, b, b_spans)\n",
    "                    if len(change) == 0 and good != bad:\n",
    "                        change = diff_char_level(good, bad) \n",
    "                except:\n",
    "                    logger.warning('error in id {}'.format(idx))\n",
    "            if len(change) == 0:\n",
    "                logger.warning('No change in id {}'.format(idx,g,b,change))\n",
    "            elif len(change) != 0 and ((change[0]['in_good'] != None and len(change[0]['in_good']['token']) > 50) or (change[0]['in_bad'] != None and len(change[0]['in_bad']['token']) > 50)):\n",
    "                logger.warning('check this - too long: %s' %idx)\n",
    "            else:\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample  \n",
    "        else:\n",
    "            try:\n",
    "                change = diff_char_level(good, bad) \n",
    "                if len(change) == 0 and good != bad:\n",
    "                    logger.warning('No change in id {}'.format(idx,g,b,change))\n",
    "                elif len(change) != 0 and ((change[0]['in_good'] != None and len(change[0]['in_good']['token']) > 30) or (change[0]['in_bad'] != None and len(change[0]['in_bad']['token']) > 30)):\n",
    "                    logger.warning('check this - too long: %s' %idx)\n",
    "                else:\n",
    "                    change = standardize_annotation(change, good, bad, maps, originals)\n",
    "                sample['annotation'] = change\n",
    "                sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "                annotations[idx] = sample\n",
    "            except: \n",
    "                logger.warning('error in id {}'.format(idx))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'units':\n",
    "        try:\n",
    "            g, b, change = annotate_units(good,bad)\n",
    "            if len(change) == 0 and g != b:\n",
    "                logger.warning('No change in id {}, \\ng: {}, \\nb: {},\\nr: {}'.format(idx, g, b))\n",
    "            elif len(change) > 1:\n",
    "                logger.warning('Multiple changes in {} id {}'.format(sample[\"phenomena\"], idx))\n",
    "            else:\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample  \n",
    "        except: \n",
    "            logger.warning('error in id {}'.format(idx))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'swap':\n",
    "        try:\n",
    "            change = annotate_swap_word_lvl(good,bad)\n",
    "            if len(change) < 2 and good != bad:\n",
    "                logger.warning('No change in id {}, \\ng: {}, \\nb: {}'.format(idx, good, bad))\n",
    "            elif change[0]['in_good'] != None and change[1]['in_good'] != None and change[0]['in_good'] == change[1]['in_good']:\n",
    "                logger.warning('check this: %s - swapped words are the same!' %idx)\n",
    "            elif (change[0]['in_good'] != None and len(change[0]['in_good']['token']) > 50) or (change[0]['in_bad'] != None and len(change[0]['in_bad']['token']) > 50):\n",
    "                logger.warning('check this: %s' %idx)\n",
    "            else:\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample\n",
    "        except: \n",
    "            logger.warning('error in id {}'.format(idx))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'date':\n",
    "        try:\n",
    "            change = diff_dates(good,bad)\n",
    "            change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample\n",
    "        except: \n",
    "            logger.warning('error in id {}'.format(idx))\n",
    "    elif phenomena[sample['phenomena']] == 'whole_sentence':\n",
    "        change = whole_sentence(good, bad)\n",
    "        change = standardize_annotation(change, good, bad, maps, originals)\n",
    "        sample['annotation'] = change\n",
    "        sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "        annotations[idx] = sample\n",
    "    if manual:\n",
    "        # if the function returns 0 it automatically accepted, if 1 skipping and if -1 exit\n",
    "        res = manual_annotation_io(idx)\n",
    "        if res == 1:  # SKIPPING\n",
    "            return 1 \n",
    "        # if exit, first save a new annotations file to save progress and then exit\n",
    "        if res == -1:\n",
    "            save_json(annotations, checkpoint)\n",
    "            return -1\n",
    "    return 1  # 1 for success\n",
    "        \n",
    "def process_phenomena(samples, manual=False, detokenize=False):\n",
    "    for idx,sample in tqdm(samples.items()):\n",
    "        if idx not in annotations.keys() and int(idx) not in annotations.keys():            \n",
    "            # check if it was annotated before\n",
    "            res = check_seen_before(sample, annotations)\n",
    "            if res != None:\n",
    "                sample['annotation'] = res[0]\n",
    "                sample['method'] = res[1]\n",
    "                annotations[int(idx)] = sample\n",
    "            else:\n",
    "                try:\n",
    "                    res = process_sample(idx, sample, manual, detokenize)\n",
    "                except:\n",
    "                    logger.error(idx)\n",
    "                if res == -1:\n",
    "                    return -1\n",
    "    # save all annotations after finished\n",
    "    save_json(annotations, checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b34c0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/c/Users/user/Desktop/work/ACES_private/challenge_set_annotation',\n",
       " '/home/arnisa/anaconda3/envs/annotate_env/lib/python38.zip',\n",
       " '/home/arnisa/anaconda3/envs/annotate_env/lib/python3.8',\n",
       " '/home/arnisa/anaconda3/envs/annotate_env/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/arnisa/anaconda3/envs/annotate_env/lib/python3.8/site-packages',\n",
       " '/mnt/c/Users/user/Desktop/work/ACES_private/challenge_set_annotation/ACES_private/span_predictions']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57baf42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnisa/anaconda3/envs/annotate_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, argparse, logging, json, glob\n",
    "from tqdm import tqdm\n",
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "logger = logging.getLogger('logger')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../span_predictions\"))\n",
    "from format_utilities import *\n",
    "sys.path.append(os.path.abspath(\"../challenge_set_annotation\"))\n",
    "from annotation_utilities import *\n",
    "sys.path.append(os.path.abspath(\"../aces\"))\n",
    "from utils import read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60e9c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_to_ACES_sample(idx, sample, manual=False):  \n",
    "    sample_out = sample.copy()\n",
    "    sample_out[\"incorrect-translation-annotated\"] = change_to_tsv_annotation(sample, m1=\"<v>\", m2=\"</v>\")\n",
    "    if manual:\n",
    "        sample_out[\"annotation-method\"] = True\n",
    "    else:\n",
    "        sample_out[\"annotation-method\"] = sample[\"method\"]\n",
    "    del sample_out[\"method\"]\n",
    "    if \"omission\" in sample_out:\n",
    "        del sample_out[\"omission\"]\n",
    "    del sample_out[\"annotation\"]\n",
    "    return sample_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9f60dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34470/34470 [00:00<00:00, 237313.28it/s]\n"
     ]
    }
   ],
   "source": [
    "annotations = read_json(\"/mnt/c/Users/user/Desktop/work/ACES_private/challenge_set_annotation/annotated.txt\")\n",
    "annotations = {int(k):v for k,v in annotations.items()}\n",
    "samples = {}\n",
    "for (idx,sample) in tqdm(annotations.items()):\n",
    "    samples[idx] = annotation_to_ACES_sample(idx, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3e5ccd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '\"Fire captain Scott said, \"\"It was a hot day in the Santa Clara with temperatures in the 90s.\"',\n",
       " 'good-translation': '\"El capitán de bomberos Scott dijo: \"\"Fue un día caliente en Santa Clara con temperaturas en los años 90.\"',\n",
       " 'incorrect-translation': '\"El capitán de bomberos Scott Kouns dijo: \"\"Fue un día caliente en Santa Clara con temperaturas en los años 90.\"',\n",
       " 'reference': 'Scott , capitán del cuartel de bomberos, comentó: «Era un día de calor en Santa Clara, con temperaturas de 90 grados.',\n",
       " 'phenomena': 'addition',\n",
       " 'langpair': 'en-es',\n",
       " 'incorrect-translation-annotated': '\"El capitán de bomberos Scott <v>Kouns</v> dijo: \"\"Fue un día caliente en Santa Clara con temperaturas en los años 90.\"',\n",
       " 'annotation-method': 'annotate_word'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d32c4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  source  \\\n",
      "ID                                                         \n",
      "0      Proper nutritional practices alone cannot gene...   \n",
      "1       has geographic variations, where the age limi...   \n",
      "2      The U.N. also hopes to finalize a fund to help...   \n",
      "3      Several million vials of vaccine have also bee...   \n",
      "4      Pre-operative people should not expect to pass...   \n",
      "...                                                  ...   \n",
      "29951    彼はノッティンガム、セルストンのブルックの娘、メアリーと結婚し、長男のリチャードに引き継いだ。   \n",
      "32324             움직임은 3x4에서 공통 섹션이 있긴 하지만 장기간에 걸쳐 있습니다.   \n",
      "32328  João Martins Pena와 Francisca de Paula Julieta ...   \n",
      "32337  하계 대학 리그의 일부인 Nashua Silver Knights는 이 도시의 현재 ...   \n",
      "32339  그는 체코의 국가 대표 선수 Jaroslav Hlinka의 사촌이자 한 때 선수였던...   \n",
      "\n",
      "                                        good-translation  \\\n",
      "ID                                                         \n",
      "0      Las prácticas nutricionales adecuadas por sí s...   \n",
      "1      tiene variaciones geográficas, donde el límite...   \n",
      "2      La ONU también espera finalizar un fondo para ...   \n",
      "3      Varios millones de frascos de vacuna también h...   \n",
      "4      Las personas preoperativas no deben esperar pa...   \n",
      "...                                                  ...   \n",
      "29951  He married Mary, the daughter of Brooke of Sel...   \n",
      "32324  Although there is a common component in 3x4, t...   \n",
      "32328  João Martins Peña and Francisco de Paula Huret...   \n",
      "32337  The Silver Knights of Nashau (part of the Summ...   \n",
      "32339  He is the cousin of Jaroslav Hlinka, a Czech n...   \n",
      "\n",
      "                                   incorrect-translation  \\\n",
      "ID                                                         \n",
      "0      Las prácticas nutricionales adecuadas por sí s...   \n",
      "1      La definición tiene variaciones geográficas, d...   \n",
      "2      La ONU también espera finalizar un fondo para ...   \n",
      "3      Varios millones de frascos de vacuna contra la...   \n",
      "4      Las personas transgénero preoperativas no debe...   \n",
      "...                                                  ...   \n",
      "29951  He married Mary, the daughter of Timothy Pusey...   \n",
      "32324  The movement is in extended time although ther...   \n",
      "32328  Was born Martins Pena in Rio de Janeiro, João ...   \n",
      "32337  The Nashua Silver Knights, part of a current s...   \n",
      "32339  He was the cousin of the Czech national player...   \n",
      "\n",
      "                                               reference        phenomena  \\\n",
      "ID                                                                          \n",
      "0      No es posible que las prácticas nutricionales ...         addition   \n",
      "1       varía geográficamente, donde el límite de eda...         addition   \n",
      "2      La ONU tiene la intención de completar un fond...         addition   \n",
      "3      Las autoridades también han garantizado varios...         addition   \n",
      "4      Las personas que aún no se han operado no debe...         addition   \n",
      "...                                                  ...              ...   \n",
      "29951  He married Mary, the daughter of Brooke of Sel...  lexical-overlap   \n",
      "32324  The movement is in extended time, although the...  lexical-overlap   \n",
      "32328  João Martins Pena and Francisca de Paula Julie...  lexical-overlap   \n",
      "32337  The Nashua Silver Knights, part of a summer co...  lexical-overlap   \n",
      "32339  He was the cousin of the Czech national player...  lexical-overlap   \n",
      "\n",
      "      langpair                    incorrect-translation-annotated  \\\n",
      "ID                                                                  \n",
      "0        en-es  Las prácticas nutricionales adecuadas por sí s...   \n",
      "1        en-es  <v>La definición</v> tiene variaciones geográf...   \n",
      "2        en-es  La ONU también espera finalizar un fondo para ...   \n",
      "3        en-es  Varios millones de frascos de vacuna <v>contra...   \n",
      "4        en-es  Las personas <v>transgénero</v> preoperativas ...   \n",
      "...        ...                                                ...   \n",
      "29951    ja-en  He married Mary, the daughter of Timothy Pusey...   \n",
      "32324    ko-en  The movement is in extended time although ther...   \n",
      "32328    ko-en  <v>Was born</v> Martins Pena in Rio de Janeiro...   \n",
      "32337    ko-en  The Nashua Silver Knights, part of a <v>curren...   \n",
      "32339    ko-en  He was the cousin of the Czech national player...   \n",
      "\n",
      "      annotation-method  \n",
      "ID                       \n",
      "0         annotate_word  \n",
      "1         annotate_word  \n",
      "2         annotate_word  \n",
      "3         annotate_word  \n",
      "4         annotate_word  \n",
      "...                 ...  \n",
      "29951            manual  \n",
      "32324            manual  \n",
      "32328            manual  \n",
      "32337            manual  \n",
      "32339            manual  \n",
      "\n",
      "[34488 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(samples, orient='index', columns=['source', 'good-translation', 'incorrect-translation', 'reference',  'phenomena', 'langpair', 'incorrect-translation-annotated', 'annotation-method'])\n",
    "# Optional: Rename the index column\n",
    "df.index.name = 'ID'\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8e8c035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0e5d803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Loading the dataset...\n",
      "INFO:logger:Dataset loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size:  36476\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(dataset_path):\n",
    "    if not os.path.exists(dataset_path):\n",
    "        logger.error('No dataset path: %s. See ACES_private/challenge_set_annotation/download_dataset.py to download it from HuggingFace' %(dataset_path))\n",
    "        exit()\n",
    "    logger.info('Loading the dataset...')\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    logger.info('Dataset loaded.')\n",
    "    return dataset['train']\n",
    "dataset = load_dataset(\"/mnt/c/Users/user/Desktop/work/dataset\")\n",
    "print('Full dataset size: ', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "819da918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>LANG</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>REANNOTATION_REASON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3038</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>The movement is in extended time, although the...</td>\n",
       "      <td>The movement is in extended time although ther...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3050</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>João Martins Pena and Francisca de Paula Julie...</td>\n",
       "      <td>&lt;Was born&gt; Martins Pena in Rio de Janeiro, &lt;Jo...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3060</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>The Nashua Silver Knights, part of a summer co...</td>\n",
       "      <td>The Nashua Silver Knights, part of a &lt;current&gt;...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6329</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>He married Mary, the daughter of Brooke of Sel...</td>\n",
       "      <td>He married Mary, the daughter of Timothy Pusey...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6348</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>The movement is in extended time, although the...</td>\n",
       "      <td>The movement is in extended time although ther...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6356</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>A CD with themes from 14 of his films was rele...</td>\n",
       "      <td>A CD with themes from fourteen of his films wa...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6375</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>The Nashua Silver Knights, part of a summer co...</td>\n",
       "      <td>The Nashua Silver Knights, part of a &lt;current&gt;...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10259</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>The movement is in extended time, although the...</td>\n",
       "      <td>The movement is in extended time although ther...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10265</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>A CD with themes from 14 of his films was rele...</td>\n",
       "      <td>A CD with themes from fourteen of his films wa...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29944</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>The Nashua Silver Knights, part of a summer co...</td>\n",
       "      <td>The Nashua Silver Knights, part of a &lt;current&gt;...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29951</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>He married Mary, the daughter of Brooke of Sel...</td>\n",
       "      <td>He married Mary, the daughter of Timothy Pusey...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32324</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>The movement is in extended time, although the...</td>\n",
       "      <td>The movement is in extended time although ther...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32328</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>João Martins Pena and Francisca de Paula Julie...</td>\n",
       "      <td>&lt;Was born&gt; Martins Pena in Rio de Janeiro, &lt;Jo...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32337</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>The Nashua Silver Knights, part of a summer co...</td>\n",
       "      <td>The Nashua Silver Knights, part of a &lt;current&gt;...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32339</td>\n",
       "      <td>word swap</td>\n",
       "      <td>en</td>\n",
       "      <td>He was the cousin of the Czech national player...</td>\n",
       "      <td>He was the cousin of the Czech national player...</td>\n",
       "      <td>Open/close error tag missing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID       TYPE LANG                                                  A  \\\n",
       "0    3038  word swap   en  The movement is in extended time, although the...   \n",
       "1    3050  word swap   en  João Martins Pena and Francisca de Paula Julie...   \n",
       "2    3060  word swap   en  The Nashua Silver Knights, part of a summer co...   \n",
       "3    6329  word swap   en  He married Mary, the daughter of Brooke of Sel...   \n",
       "4    6348  word swap   en  The movement is in extended time, although the...   \n",
       "5    6356  word swap   en  A CD with themes from 14 of his films was rele...   \n",
       "6    6375  word swap   en  The Nashua Silver Knights, part of a summer co...   \n",
       "7   10259  word swap   en  The movement is in extended time, although the...   \n",
       "8   10265  word swap   en  A CD with themes from 14 of his films was rele...   \n",
       "9   29944  word swap   en  The Nashua Silver Knights, part of a summer co...   \n",
       "10  29951  word swap   en  He married Mary, the daughter of Brooke of Sel...   \n",
       "11  32324  word swap   en  The movement is in extended time, although the...   \n",
       "12  32328  word swap   en  João Martins Pena and Francisca de Paula Julie...   \n",
       "13  32337  word swap   en  The Nashua Silver Knights, part of a summer co...   \n",
       "14  32339  word swap   en  He was the cousin of the Czech national player...   \n",
       "\n",
       "                                                    B  \\\n",
       "0   The movement is in extended time although ther...   \n",
       "1   <Was born> Martins Pena in Rio de Janeiro, <Jo...   \n",
       "2   The Nashua Silver Knights, part of a <current>...   \n",
       "3   He married Mary, the daughter of Timothy Pusey...   \n",
       "4   The movement is in extended time although ther...   \n",
       "5   A CD with themes from fourteen of his films wa...   \n",
       "6   The Nashua Silver Knights, part of a <current>...   \n",
       "7   The movement is in extended time although ther...   \n",
       "8   A CD with themes from fourteen of his films wa...   \n",
       "9   The Nashua Silver Knights, part of a <current>...   \n",
       "10  He married Mary, the daughter of Timothy Pusey...   \n",
       "11  The movement is in extended time although ther...   \n",
       "12  <Was born> Martins Pena in Rio de Janeiro, <Jo...   \n",
       "13  The Nashua Silver Knights, part of a <current>...   \n",
       "14  He was the cousin of the Czech national player...   \n",
       "\n",
       "             REANNOTATION_REASON  \n",
       "0                    Unannotated  \n",
       "1                    Unannotated  \n",
       "2                    Unannotated  \n",
       "3                    Unannotated  \n",
       "4                    Unannotated  \n",
       "5                    Unannotated  \n",
       "6                    Unannotated  \n",
       "7                    Unannotated  \n",
       "8                    Unannotated  \n",
       "9                    Unannotated  \n",
       "10                   Unannotated  \n",
       "11                   Unannotated  \n",
       "12                   Unannotated  \n",
       "13                   Unannotated  \n",
       "14  Open/close error tag missing  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a942695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>good-translation</th>\n",
       "      <th>incorrect-translation</th>\n",
       "      <th>reference</th>\n",
       "      <th>phenomena</th>\n",
       "      <th>langpair</th>\n",
       "      <th>incorrect-translation-annotated</th>\n",
       "      <th>annotation-method</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Proper nutritional practices alone cannot gene...</td>\n",
       "      <td>Las prácticas nutricionales adecuadas por sí s...</td>\n",
       "      <td>Las prácticas nutricionales adecuadas por sí s...</td>\n",
       "      <td>No es posible que las prácticas nutricionales ...</td>\n",
       "      <td>addition</td>\n",
       "      <td>en-es</td>\n",
       "      <td>Las prácticas nutricionales adecuadas por sí s...</td>\n",
       "      <td>annotate_word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has geographic variations, where the age limi...</td>\n",
       "      <td>tiene variaciones geográficas, donde el límite...</td>\n",
       "      <td>La definición tiene variaciones geográficas, d...</td>\n",
       "      <td>varía geográficamente, donde el límite de eda...</td>\n",
       "      <td>addition</td>\n",
       "      <td>en-es</td>\n",
       "      <td>&lt;v&gt;La definición&lt;/v&gt; tiene variaciones geográf...</td>\n",
       "      <td>annotate_word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The U.N. also hopes to finalize a fund to help...</td>\n",
       "      <td>La ONU también espera finalizar un fondo para ...</td>\n",
       "      <td>La ONU también espera finalizar un fondo para ...</td>\n",
       "      <td>La ONU tiene la intención de completar un fond...</td>\n",
       "      <td>addition</td>\n",
       "      <td>en-es</td>\n",
       "      <td>La ONU también espera finalizar un fondo para ...</td>\n",
       "      <td>annotate_word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Several million vials of vaccine have also bee...</td>\n",
       "      <td>Varios millones de frascos de vacuna también h...</td>\n",
       "      <td>Varios millones de frascos de vacuna contra la...</td>\n",
       "      <td>Las autoridades también han garantizado varios...</td>\n",
       "      <td>addition</td>\n",
       "      <td>en-es</td>\n",
       "      <td>Varios millones de frascos de vacuna &lt;v&gt;contra...</td>\n",
       "      <td>annotate_word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pre-operative people should not expect to pass...</td>\n",
       "      <td>Las personas preoperativas no deben esperar pa...</td>\n",
       "      <td>Las personas transgénero preoperativas no debe...</td>\n",
       "      <td>Las personas que aún no se han operado no debe...</td>\n",
       "      <td>addition</td>\n",
       "      <td>en-es</td>\n",
       "      <td>Las personas &lt;v&gt;transgénero&lt;/v&gt; preoperativas ...</td>\n",
       "      <td>annotate_word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               source  \\\n",
       "ID                                                      \n",
       "0   Proper nutritional practices alone cannot gene...   \n",
       "1    has geographic variations, where the age limi...   \n",
       "2   The U.N. also hopes to finalize a fund to help...   \n",
       "3   Several million vials of vaccine have also bee...   \n",
       "4   Pre-operative people should not expect to pass...   \n",
       "\n",
       "                                     good-translation  \\\n",
       "ID                                                      \n",
       "0   Las prácticas nutricionales adecuadas por sí s...   \n",
       "1   tiene variaciones geográficas, donde el límite...   \n",
       "2   La ONU también espera finalizar un fondo para ...   \n",
       "3   Varios millones de frascos de vacuna también h...   \n",
       "4   Las personas preoperativas no deben esperar pa...   \n",
       "\n",
       "                                incorrect-translation  \\\n",
       "ID                                                      \n",
       "0   Las prácticas nutricionales adecuadas por sí s...   \n",
       "1   La definición tiene variaciones geográficas, d...   \n",
       "2   La ONU también espera finalizar un fondo para ...   \n",
       "3   Varios millones de frascos de vacuna contra la...   \n",
       "4   Las personas transgénero preoperativas no debe...   \n",
       "\n",
       "                                            reference phenomena langpair  \\\n",
       "ID                                                                         \n",
       "0   No es posible que las prácticas nutricionales ...  addition    en-es   \n",
       "1    varía geográficamente, donde el límite de eda...  addition    en-es   \n",
       "2   La ONU tiene la intención de completar un fond...  addition    en-es   \n",
       "3   Las autoridades también han garantizado varios...  addition    en-es   \n",
       "4   Las personas que aún no se han operado no debe...  addition    en-es   \n",
       "\n",
       "                      incorrect-translation-annotated annotation-method  \n",
       "ID                                                                       \n",
       "0   Las prácticas nutricionales adecuadas por sí s...     annotate_word  \n",
       "1   <v>La definición</v> tiene variaciones geográf...     annotate_word  \n",
       "2   La ONU también espera finalizar un fondo para ...     annotate_word  \n",
       "3   Varios millones de frascos de vacuna <v>contra...     annotate_word  \n",
       "4   Las personas <v>transgénero</v> preoperativas ...     annotate_word  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d20788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>LANG</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>REANNOTATION_REASON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19552</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>de</td>\n",
       "      <td>Zuvor bemerkte der CEO von Ring, Jamie Siminof...</td>\n",
       "      <td>Zuvor bemerkte der CEO von Ring, Jamie Siminof...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25218</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>de</td>\n",
       "      <td>Aber nach dem Verlust des Schalters seines Kap...</td>\n",
       "      <td>Aber nach dem Verlust des Schalters seines Kap...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25253</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>de</td>\n",
       "      <td>Virtuelle Steckdosen sind in die Software inte...</td>\n",
       "      <td>Virtuelle Steckdosen sind in die Software inte...</td>\n",
       "      <td>Unannotated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index     ID           TYPE LANG  \\\n",
       "0        0      0  19552  hallucination   de   \n",
       "1        1      1  25218  hallucination   de   \n",
       "2        2      2  25253  hallucination   de   \n",
       "\n",
       "                                                   A  \\\n",
       "0  Zuvor bemerkte der CEO von Ring, Jamie Siminof...   \n",
       "1  Aber nach dem Verlust des Schalters seines Kap...   \n",
       "2  Virtuelle Steckdosen sind in die Software inte...   \n",
       "\n",
       "                                                   B REANNOTATION_REASON  \n",
       "0  Zuvor bemerkte der CEO von Ring, Jamie Siminof...         Unannotated  \n",
       "1  Aber nach dem Verlust des Schalters seines Kap...         Unannotated  \n",
       "2  Virtuelle Steckdosen sind in die Software inte...         Unannotated  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "243fb86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/mnt/c/Users/user/Desktop/work/manual_annotations/Annotation_SecondDelivery/annotated_EN_for_reannotation.tsv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6252b4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '하계 대학 리그의 일부인 Nashua Silver Knights는 이 도시의 현재 팀이다.',\n",
       " 'good-translation': \"The Silver Knights of Nashau (part of the Summer University Alliance) are now the city's team.\",\n",
       " 'incorrect-translation': 'The Nashua Silver Knights, part of a current summer league, is the collegiate team of the city.',\n",
       " 'reference': \"The Nashua Silver Knights, part of a summer collegiate league, is today's team in the city.\",\n",
       " 'phenomena': 'lexical-overlap',\n",
       " 'langpair': 'ko-en',\n",
       " 'incorrect-translation-annotated': 'The Nashua Silver Knights, part of a <v>current</v> summer league, is the <v>collegiate</v> team of the city.'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[32337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f02d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to start from the beginning - not from a checkpoint (you will lose the prev checkpoint tho)\n",
    "annotations = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1d437a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:10<00:00, 95.50it/s] \n"
     ]
    }
   ],
   "source": [
    "# THE ACTUAL PART\n",
    "logger.setLevel(logging.INFO)\n",
    "stats = {}\n",
    "for key in [phenomena_tobe_processed]:\n",
    "    stats[key] = copy.deepcopy(stats_template)\n",
    "process_phenomena(samples, manual=False, detokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2acac373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '\"Fire captain Scott said, \"\"It was a hot day in the Santa Clara with temperatures in the 90s.\"',\n",
       " 'good-translation': '\"El capitán de bomberos Scott dijo: \"\"Fue un día caliente en Santa Clara con temperaturas en los años 90.\"',\n",
       " 'incorrect-translation': '\"El capitán de bomberos Scott Kouns dijo: \"\"Fue un día caliente en Santa Clara con temperaturas en los años 90.\"',\n",
       " 'reference': 'Scott , capitán del cuartel de bomberos, comentó: «Era un día de calor en Santa Clara, con temperaturas de 90 grados.',\n",
       " 'phenomena': 'addition',\n",
       " 'langpair': 'en-es',\n",
       " 'annotation': ([{'in_bad': {'token_index': [6],\n",
       "     'character_span': (30, 35),\n",
       "     'token': 'Kouns'},\n",
       "    'in_good': None}],\n",
       "  False),\n",
       " 'method': 'annotate_word'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e63d963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoint, \"w+\") as f:\n",
    "    json.dump(str(annotations), f, indent=2, ensure_ascii=False)  # encode dict into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bf029e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 782572; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/user/Desktop/work/ACES_private/challenge_set_annotation/annotations.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/work/ACES_private/challenge_set_annotation/annotations.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(checkpoint, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/work/ACES_private/challenge_set_annotation/annotations.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     annotations \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(\u001b[39mdict\u001b[39;49m(f))\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 782572; 2 is required"
     ]
    }
   ],
   "source": [
    "with open(checkpoint, \"r\") as f:\n",
    "    annotations = json.load(dict(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3cc89297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Your data to be serialized\n",
    "data = {\n",
    "    \"name\": \"John\",\n",
    "    \"description\": \"Contains special characters like é, ç, and ∆.\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Serialize the data to a JSON file with the custom encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6e3380ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'description': 'Contains special characters like é, ç, and ∆.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a custom JSON decoder to handle special characters\n",
    "\n",
    "\n",
    "# Read the data from the JSON file into a dictionary\n",
    "\n",
    "\n",
    "# Now, 'loaded_data' contains the dictionary from the JSON file, including special characters\n",
    "print(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After this cell there are extra stuff - no need to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1bce7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run normalization over the already annotated samples in coreference-based-on-commonsense\n",
    "# No need to do that for manual annotation!\n",
    "for idx in annotations:\n",
    "    sample = annotations[idx]\n",
    "    good, _, _ = ref_or_good(sample[\"reference\"], sample[\"good-translation\"], sample[\"incorrect-translation\"])\n",
    "    bad = sample['incorrect-translation']\n",
    "    change = sample['annotation']\n",
    "    try:\n",
    "        sample['annotation'] = standardize_annotation(change, good, bad)\n",
    "    except:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5871f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoint, \"w+\") as f:\n",
    "    json.dump(annotations, f, indent=2, ensure_ascii=False)  # encode dict into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fc91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for checking if all langpairs are correct\n",
    "langpairs = set()\n",
    "for sample in dataset[\"train\"]:\n",
    "    langpairs.add(sample[\"langpair\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f26a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "langpairs_keys = list(langpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to count the number of samples in any phenomena\n",
    "# No need to do that for manual annotation!\n",
    "basic_lang = ['en', 'de', 'fr', 'mr', 'tr']\n",
    "for p in ['coreference-based-on-commonsense', 'lexical-overlap',\n",
    "         'xnli-addition-contradiction', 'xnli-addition-neutral',\n",
    "         'xnli-omission-contradiction', 'xnli-omission-neutral']:\n",
    "    print(\"**********************\", p)\n",
    "    l_found = dict(zip(langpairs_keys, np.zeros(len(langpairs))))\n",
    "    for sample in dataset[\"train\"]:\n",
    "        src, tgt = sample[\"langpair\"].split('-')\n",
    "        if sample['phenomena'] == p and l_found[sample[\"langpair\"]] == 0 and (src not in basic_lang or tgt not in basic_lang):\n",
    "            print(sample[\"langpair\"], \": \\n\\t\", sample['source'], \"\\n\\t\", sample['good-translation'])\n",
    "            l_found[sample[\"langpair\"]] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annotate_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
