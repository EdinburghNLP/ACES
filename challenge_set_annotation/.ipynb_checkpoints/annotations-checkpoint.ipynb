{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b96d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the phenomena: real-world-knowledge-hypernym-vs-distractor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Loading the dataset...\n",
      "INFO:logger:Dataset loaded.\n",
      "INFO:logger:Creating new stats.txt file at /mnt/c/Users/user/OneDrive/Masaüstü/work/ACES_private/challenge_set_annotation/ACES_private/challenge_set_annotation/stats.txt\n",
      "INFO:logger:READY\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import json, copy, os, sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('logger')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n",
    "from annotation_utilities import *\n",
    "\n",
    "# this is the list of phenomena and which option they need to be annotated with:\n",
    "phenomena = {\n",
    "    'addition':'add-omit',\n",
    "    'ambiguous-translation-wrong-discourse-connective-since-causal':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-discourse-connective-since-temporal':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-discourse-connective-while-contrast':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-discourse-connective-while-temporal':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-gender-female-anti':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-gender-female-pro':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-gender-male-anti':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-gender-male-pro':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-sense-frequent':'diff_flexible',\n",
    "    'ambiguous-translation-wrong-sense-infrequent':'diff_flexible',\n",
    "    'anaphoric_group_it-they:deletion':'annotate_word',\n",
    "    'anaphoric_group_it-they:substitution':'annotate_word',\n",
    "    'anaphoric_intra_non-subject_it:deletion':'annotate_word',\n",
    "    'anaphoric_intra_non-subject_it:substitution':'annotate_word',\n",
    "    'anaphoric_intra_subject_it:deletion':'annotate_word',\n",
    "    'anaphoric_intra_subject_it:substitution':'annotate_word',\n",
    "    'anaphoric_intra_they:deletion':'annotate_word',\n",
    "    'anaphoric_intra_they:substitution':'annotate_word',\n",
    "    'anaphoric_singular_they:deletion':'annotate_word',\n",
    "    'anaphoric_singular_they:substitution':'annotate_word',\n",
    "    'antonym-replacement':'REF_flexible',\n",
    "    'commonsense-only-ref-ambiguous':'diff_flexible',\n",
    "    'commonsense-src-and-ref-ambiguous':'diff_flexible',\n",
    "    'copy-source':'whole_sentence',\n",
    "    'coreference-based-on-commonsense':'mixed_flexible',\n",
    "    'do-not-translate':'whole_sentence',\n",
    "    'hallucination-date-time':'date',\n",
    "    'hallucination-named-entity-level-1':'diff_flexible',\n",
    "    'hallucination-named-entity-level-2':'REF_flexible',\n",
    "    'hallucination-named-entity-level-3':'REF_flexible',\n",
    "    'hallucination-number-level-1':'diff_flexible',\n",
    "    'hallucination-number-level-2':'REF_flexible',\n",
    "    'hallucination-number-level-3':'REF_flexible',\n",
    "    'hallucination-real-data-vs-ref-word':'diff_flexible',\n",
    "    'hallucination-real-data-vs-synonym':'diff_flexible',\n",
    "    'hallucination-unit-conversion-amount-matches-ref':'units',\n",
    "    'hallucination-unit-conversion-unit-matches-ref':'units',\n",
    "    'hypernym-replacement':'REF_flexible',\n",
    "    'hyponym-replacement':'REF_flexible',\n",
    "    'lexical-overlap':'?',\n",
    "    'modal_verb:deletion':'add-omit',\n",
    "    'modal_verb:substitution':'diff_flexible',\n",
    "    'nonsense':'REF_flexible',\n",
    "    'omission':'add-omit',\n",
    "    'ordering-mismatch':'swap',\n",
    "    'overly-literal-vs-correct-idiom':'diff_flexible',\n",
    "    'overly-literal-vs-explanation':'diff_flexible',\n",
    "    'overly-literal-vs-ref-word':'diff_flexible',\n",
    "    'overly-literal-vs-synonym':'diff_flexible',\n",
    "    'pleonastic_it:deletion':'annotate_word',\n",
    "    'pleonastic_it:substitution':'annotate_word',\n",
    "    'punctuation:deletion_all':'add-omit',\n",
    "    'punctuation:deletion_commas':'add-omit',\n",
    "    'punctuation:deletion_quotes':'add-omit',\n",
    "    'punctuation:statement-to-question':'add-omit',\n",
    "    'real-world-knowledge-entailment':'diff_flexible',\n",
    "    'real-world-knowledge-hypernym-vs-distractor':'diff_flexible',\n",
    "    'real-world-knowledge-hypernym-vs-hyponym':'diff_flexible',\n",
    "    'real-world-knowledge-synonym-vs-antonym':'diff_flexible',\n",
    "    'similar-language-high':'whole_sentence',\n",
    "    'similar-language-low':'whole_sentence',\n",
    "    'untranslated-vs-ref-word':'diff_flexible',   # here add-omit can be used for getting character level replacements too\n",
    "    'untranslated-vs-synonym':'diff_flexible',\n",
    "    'xnli-addition-contradiction':'?',\n",
    "    'xnli-addition-neutral':'?',\n",
    "    'xnli-omission-contradiction':'?',\n",
    "    'xnli-omission-neutral':'?'\n",
    "}\n",
    "\n",
    "folder = os.getcwd()\n",
    "manual_annotations = os.path.join(folder, 'manual_annotations')\n",
    "if not os.path.exists(manual_annotations):\n",
    "    os.mkdir(manual_annotations)\n",
    "    \n",
    "phenomena_tobe_processed = input(\"enter the phenomena: \") \n",
    "if phenomena_tobe_processed == 'test':\n",
    "    # load the subset.json\n",
    "    dataset_path = os.path.join(manual_annotations, 'subset.json')\n",
    "    if not os.path.exists(dataset_path):\n",
    "        logger.error('No dataset path: %s' %(dataset_path))\n",
    "        exit()\n",
    "    logger.info('Loading the test dataset...')\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        samples = json.load(f)\n",
    "    logger.info('Test dataset loaded.')\n",
    "elif phenomena_tobe_processed not in phenomena.keys():\n",
    "    logger.error(\"The phenomena should be one of these: {}\".format(sys.argv[1], phenomena.keys()))\n",
    "    exit()\n",
    "else:\n",
    "    dataset_path = os.path.join(folder, '../../dataset')\n",
    "    if not os.path.exists(dataset_path):\n",
    "        logger.error('No dataset path: %s' %(dataset_path))\n",
    "        exit()\n",
    "    logger.info('Loading the dataset...')\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    logger.info('Dataset loaded.')\n",
    "    samples = dict()\n",
    "    for idx, sample in enumerate(dataset['train']):\n",
    "        if sample['phenomena'] in phenomena_tobe_processed:\n",
    "            samples[idx] = sample\n",
    "        \n",
    "checkpoint = os.path.join(folder, 'manual_annotations/annotated_checkpoint_{}.txt'.format(phenomena_tobe_processed))\n",
    "if os.path.exists(checkpoint):\n",
    "    logger.info('Path {} already exists. Loading..'.format(checkpoint))\n",
    "    with open(checkpoint, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "    annotations = {int(k):v for k,v in annotations.items()}\n",
    "else:\n",
    "    annotations = dict()\n",
    "    \n",
    "# calculate statistics about the annotations:\n",
    "# for every mode, calculate no. of skipped, no. of unsure and ids, and no. of done.\n",
    "stats_template = {\n",
    "            'total':0,\n",
    "            'success':0,\n",
    "            'too_long':[],\n",
    "            'no_change':[],\n",
    "            'error':[],\n",
    "            'other':[]  \n",
    "        }\n",
    "stats_path = os.path.join(folder, 'ACES_private/challenge_set_annotation/stats.txt')\n",
    "if os.path.exists(stats_path):\n",
    "    logger.info('Path {} already exists. Loading..'.format(stats_path))\n",
    "    with open(stats_path, \"r\") as f:\n",
    "        stats = json.load(f)\n",
    "    # we want to overwrite the statistics for the new phenomena\n",
    "    for p in phenomena_tobe_processed:\n",
    "        stats[p] = copy.deepcopy(stats_template)\n",
    "else:\n",
    "    logger.info('Creating new stats.txt file at {}'.format(stats_path))\n",
    "    stats = {}\n",
    "    for key in phenomena.keys():\n",
    "        stats[key] = copy.deepcopy(stats_template)\n",
    "    stats['test'] = copy.deepcopy(stats_template)\n",
    "    \n",
    "            \n",
    "logger.info(\"READY\")\n",
    "\n",
    "# the UI (?) part of the annotation in general (ask if they want to accept the annotation, call manual_annotation if no)\n",
    "def manual_annotation_io(idx):\n",
    "    sample = samples[idx]\n",
    "    if idx in annotations:\n",
    "        change = annotations[idx]['annotation']   # now it's normalized annotation.\n",
    "        if len(change) == 1 and len(change[0][\"in_good\"]['token_index']) == len(change[0][\"in_bad\"]['token_index']):\n",
    "            return 0\n",
    "    if phenomena[sample[\"phenomena\"]] in ['?', 'mixed_flexible']:\n",
    "        print(\"-----> For this sample we can compare the Incorrect translation with either Reference or Good translation.\")\n",
    "    elif phenomena[sample[\"phenomena\"]] in ['REF_flexible']:\n",
    "        print(\"-----> For this sample we compare the Incorrect translation with the Reference.\")\n",
    "    else:\n",
    "        print(\"-----> For this sample we compare the Incorrect translation with the Good translation.\\n\")\n",
    "    if idx in annotations:\n",
    "        print(\"\\nID: \", idx)\n",
    "        print(\"Source sentence: \", sample['source'])\n",
    "        print(\"Reference: \", sample['reference'])\n",
    "        print(\"Good Translation: \", sample['good-translation'])\n",
    "        print(\"Incorrect Translation: \", sample['incorrect-translation'])\n",
    "        print('Suggested annotation:')\n",
    "        print(annotations[idx]['annotation'], '\\n')\n",
    "        inp = input('To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:')\n",
    "        if inp == \"skip\":\n",
    "            annotations.pop(idx)\n",
    "            return 1  # this means, we are skipping, so should delete this annotation and then continue with the next.\n",
    "        res = manual_annotation(idx, inp)\n",
    "        if res == -1:\n",
    "            # do not add the annotation if you stop at this point\n",
    "            annotations.pop(idx)\n",
    "            return -1\n",
    "    else:\n",
    "        print(\"No automatic translations for this sample.\")\n",
    "        res = manual_annotation(idx)\n",
    "        if res == -1:\n",
    "            return -1\n",
    "\n",
    "# the UI (?) part of the manual annotation\n",
    "def manual_annotation(idx, inp=\".\"):\n",
    "    while inp != \"\":\n",
    "        sample = samples[idx]\n",
    "        print(\"Source sentence: \", sample['source'])\n",
    "        print(\"Reference: \", sample['reference'])\n",
    "        print(\"Good Translation: \", sample['good-translation'])\n",
    "        print(\"Incorrect Translation: \", sample['incorrect-translation'])\n",
    "        inp = input(\"Enter the incorrect translation with the < and > to show the error spans (exit to stop): \\n\")\n",
    "        bad = inp\n",
    "        if bad == \"exit\":\n",
    "            return -1\n",
    "        inp = input(\"Enter the correct/reference translation with the < and > to show the error spans (exit to stop): \\n\")\n",
    "        good = inp\n",
    "        if good == \"exit\":\n",
    "            return -1\n",
    "        change = calculate_change(good, bad, sample)\n",
    "        print(\"Annotation: \", change)\n",
    "        inp = input(\"\\n To accept it press enter or to annotate again enter any other string: \")\n",
    "        if inp == \"\":\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = \"manual annotation\"\n",
    "            annotations[idx] = sample\n",
    "    return annotations[idx]\n",
    "\n",
    "# given a manually annotated sample (where there are <> in incorrect and good/reference sentences)\n",
    "# calculate the character spans in the original sentences and return the change in our annotation format\n",
    "def calculate_change(good, bad, sample):  \n",
    "    bad_id = 0\n",
    "    span = False # False is when we are not inside a span, True is inside a span\n",
    "    change = []\n",
    "    for i, c in enumerate(bad):\n",
    "        if c == \"<\":\n",
    "            if span:\n",
    "                logger.error(\"< not closed. Try again.\\n\")\n",
    "                return manual_annotation(\".\", sample)\n",
    "            else:\n",
    "                start = bad_id\n",
    "                start_annotate = i\n",
    "                bad_id -= 1\n",
    "                span = True\n",
    "        elif c == \">\":\n",
    "            if not span:\n",
    "                logger.error(\"No opening < Try again.\\n\")\n",
    "                return manual_annotation(\".\", sample)\n",
    "            else:\n",
    "                change.append({\"in_good\":None, \n",
    "                    \"in_bad\":{'token_index':None, \n",
    "                    'character_span':(start,bad_id), \n",
    "                               'token':bad[start_annotate+1:i]}})\n",
    "                bad_id -= 1\n",
    "                span = False\n",
    "        bad_id += 1\n",
    "    good_id = 0\n",
    "    span = False # False is when we are not inside a span, True is inside a span\n",
    "    for i, c in enumerate(good):\n",
    "        if c == \"<\":\n",
    "            if span:\n",
    "                logger.error(\"< not closed. Try again.\\n\")\n",
    "                return manual_annotation(\".\", sample)\n",
    "            else:\n",
    "                start = good_id\n",
    "                start_annotate = i\n",
    "                good_id -= 1\n",
    "                span = True\n",
    "        elif c == \">\":\n",
    "            if not span:\n",
    "                logger.error(\"No opening < Try again.\\n\")\n",
    "                return manual_annotation(\".\", sample)\n",
    "            else:\n",
    "                change.append({\"in_good\":{'token_index':None, \n",
    "                    'character_span':(start,good_id), \n",
    "                               'token':good[start_annotate+1:i]}, \n",
    "                    \"in_bad\":None})\n",
    "                good_id -= 1\n",
    "                span = False\n",
    "        good_id += 1\n",
    "    return change\n",
    "\n",
    "# process given sample, annotate or do manual annotation (only in the annotations.ipynb, in process_dataset.py only automatic annotation)\n",
    "def process_sample(idx, sample, manual=False, detokenize=False):\n",
    "    if phenomena[sample[\"phenomena\"]] == 'mixed_flexible':\n",
    "        good_og = ref_or_good(sample[\"reference\"], sample[\"good-translation\"], sample[\"incorrect-translation\"])\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'REF_flexible':\n",
    "        good_og = sample[\"reference\"]\n",
    "    else:\n",
    "        good_og = sample[\"good-translation\"]\n",
    "    bad_og = sample[\"incorrect-translation\"]\n",
    "    # if detokenize we just annotate the detokenized sentences, then map the character span back to the original sentence\n",
    "    # in the standardize_annotation function in annotation_utilities.py\n",
    "    if detokenize:\n",
    "        try:\n",
    "            good, good_map = detokenize_text(good_og, lang=sample[\"langpair\"].split('-')[1])\n",
    "            bad, bad_map = detokenize_text(bad_og, lang=sample[\"langpair\"].split('-')[1])\n",
    "            maps = (good_map, bad_map)\n",
    "        except:\n",
    "            good, bad = good_og, bad_og\n",
    "            maps = None\n",
    "    else:\n",
    "        good, bad = good_og, bad_og\n",
    "        maps = None # the standardize_annotation function will understand that it does not need to revert detokenization \n",
    "        # if maps parameter is None.\n",
    "    originals = (good_og, bad_og)\n",
    "    \n",
    "    if phenomena[sample[\"phenomena\"]] == 'add-omit':\n",
    "        try:\n",
    "            change = diff_char_level(good, bad)\n",
    "            if len(change) == 0:\n",
    "                logger.warning('No change in id {}'.format(idx))\n",
    "                stats[sample[\"phenomena\"]][\"no_change\"].append((idx, sample['langpair']))\n",
    "            else:\n",
    "                stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample\n",
    "        except:\n",
    "            logger.warning('error in char level annotate, id {}'.format(idx))\n",
    "            stats[sample[\"phenomena\"]][\"error\"].append((idx, sample['langpair']))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'annotate_word':\n",
    "        try:\n",
    "            change = annotate_word(good, bad)\n",
    "            if len(change) == 0:\n",
    "                logger.warning('No change in id {}'.format(idx))\n",
    "                stats[sample[\"phenomena\"]][\"no_change\"].append((idx, sample['langpair']))\n",
    "            else:\n",
    "                stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample\n",
    "        except:\n",
    "            logger.warning('error in word level annotate, id {}'.format(idx))\n",
    "            stats[sample[\"phenomena\"]][\"error\"].append((idx, sample['langpair']))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] in ['diff_flexible', 'REF_flexible', 'mixed_flexible']:\n",
    "        g, g_spans = tokenize(good)\n",
    "        b, b_spans = tokenize(bad)\n",
    "\n",
    "        # special treatment to japanese chinese and thailandish because they don't use spaces, so can't be split            \n",
    "        if sample['langpair'][-2:] not in ['ja', 'zh', 'th']:      \n",
    "            if len(g) == len(b):   # if there are multiple one word replacements\n",
    "                change = diff(g, g_spans, b, b_spans, phenomena=\"replacement\")\n",
    "            if len(g) != len(b) or len(change) == 0:\n",
    "                try:\n",
    "                    change = diff_flexible(good, g, g_spans, bad, b, b_spans)\n",
    "                    if len(change) == 0 and good != bad:\n",
    "                        change = diff_char_level(good, bad) \n",
    "                except:\n",
    "                    logger.warning('error in id {}'.format(idx))\n",
    "                    stats[sample[\"phenomena\"]][\"error\"].append((idx, sample['langpair']))\n",
    "            if len(change) == 0:\n",
    "                logger.warning('No change in id {}'.format(idx,g,b,change))\n",
    "                stats[sample[\"phenomena\"]][\"no_change\"].append((idx, sample['langpair']))\n",
    "            elif len(change) != 0 and ((change[0]['in_good'] != None and len(change[0]['in_good']['token']) > 50) or (change[0]['in_bad'] != None and len(change[0]['in_bad']['token']) > 50)):\n",
    "                logger.warning('check this - too long: %s' %idx)\n",
    "                stats[sample[\"phenomena\"]][\"too_long\"].append((idx, sample['langpair']))\n",
    "            else:\n",
    "                stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample  \n",
    "        else:\n",
    "            try:\n",
    "                change = diff_char_level(good, bad) \n",
    "                if len(change) == 0 and good != bad:\n",
    "                    logger.warning('No change in id {}'.format(idx,g,b,change))\n",
    "                    stats[sample[\"phenomena\"]][\"no_change\"].append((idx, sample['langpair']))\n",
    "                elif len(change) != 0 and ((change[0]['in_good'] != None and len(change[0]['in_good']['token']) > 30) or (change[0]['in_bad'] != None and len(change[0]['in_bad']['token']) > 30)):\n",
    "                    logger.warning('check this - too long: %s' %idx)\n",
    "                    stats[sample[\"phenomena\"]][\"too_long\"].append((idx, sample['langpair']))\n",
    "                else:\n",
    "                    stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "                    change = standardize_annotation(change, good, bad, maps, originals)\n",
    "                sample['annotation'] = change\n",
    "                sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "                annotations[idx] = sample\n",
    "            except: \n",
    "                logger.warning('error in id {}'.format(idx))\n",
    "                stats[sample[\"phenomena\"]][\"error\"].append((idx, sample['langpair']))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'units':\n",
    "        try:\n",
    "            g, b, change = annotate_units(good,bad)\n",
    "            if len(change) == 0 and g != b:\n",
    "                logger.warning('No change in id {}, \\ng: {}, \\nb: {},\\nr: {}'.format(idx, g, b))\n",
    "                stats[sample[\"phenomena\"]][\"no_change\"].append((idx, sample['langpair']))\n",
    "            elif len(change) > 1:\n",
    "                logger.warning('Multiple changes in {} id {}'.format(sample[\"phenomena\"], idx))\n",
    "                stats[sample[\"phenomena\"]][\"other\"].append((idx, sample['langpair']))\n",
    "            else:\n",
    "                stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample  \n",
    "        except: \n",
    "            logger.warning('error in id {}'.format(idx))\n",
    "            stats[sample[\"phenomena\"]][\"error\"].append((idx, sample['langpair']))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'swap':\n",
    "        try:\n",
    "            change = annotate_swap_word_lvl(good,bad)\n",
    "            if len(change) < 2 and good != bad:\n",
    "                logger.warning('No change in id {}, \\ng: {}, \\nb: {}'.format(idx, good, bad))\n",
    "                stats[sample[\"phenomena\"]][\"no_change\"].append((idx, sample['langpair']))\n",
    "            elif change[0]['in_good'] != None and change[1]['in_good'] != None and change[0]['in_good'] == change[1]['in_good']:\n",
    "                logger.warning('check this: %s - swapped words are the same!' %idx)\n",
    "                stats[sample[\"phenomena\"]][\"other\"].append((idx, sample['langpair']))\n",
    "            elif (change[0]['in_good'] != None and len(change[0]['in_good']['token']) > 50) or (change[0]['in_bad'] != None and len(change[0]['in_bad']['token']) > 50):\n",
    "                logger.warning('check this: %s' %idx)\n",
    "                stats[sample[\"phenomena\"]][\"too_long\"].append((idx, sample['langpair']))\n",
    "            else:\n",
    "                stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "                change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample\n",
    "        except: \n",
    "            logger.warning('error in id {}'.format(idx))\n",
    "            stats[sample[\"phenomena\"]][\"error\"].append((idx, sample['langpair']))\n",
    "\n",
    "    elif phenomena[sample[\"phenomena\"]] == 'date':\n",
    "        try:\n",
    "            change = diff_dates(good,bad)\n",
    "            stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "            change = standardize_annotation(change, good, bad, maps, originals)\n",
    "            sample['annotation'] = change\n",
    "            sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "            annotations[idx] = sample\n",
    "        except: \n",
    "            logger.warning('error in id {}'.format(idx))\n",
    "            stats[sample[\"phenomena\"]][\"error\"].append((idx, sample['langpair']))\n",
    "    elif phenomena[sample['phenomena']] == 'whole_sentence':\n",
    "        change = whole_sentence(good, bad)\n",
    "        stats[sample[\"phenomena\"]][\"success\"] += 1\n",
    "        change = standardize_annotation(change, good, bad, maps, originals)\n",
    "        sample['annotation'] = change\n",
    "        sample['method'] = phenomena[sample[\"phenomena\"]]\n",
    "        annotations[idx] = sample\n",
    "    if manual:\n",
    "        res = manual_annotation_io(idx)\n",
    "        if res == 1:  # SKIPPING\n",
    "            return 1 \n",
    "        # if exit, first save a new annotations file to save progress and then exit\n",
    "        if res == -1:\n",
    "            with open(checkpoint, \"w+\") as f:\n",
    "                json.dump(annotations, f, indent=2, ensure_ascii=False)  # encode dict into JSON\n",
    "            return -1\n",
    "    return 1  # 1 for success\n",
    "        \n",
    "def process_phenomena(samples, manual=False, detokenize=False):\n",
    "    for idx,sample in tqdm(samples.items()):\n",
    "        # here don't worry about stats - it will be probably completely wrong\n",
    "        if idx not in annotations.keys():\n",
    "            stats[sample[\"phenomena\"]][\"total\"] += 1\n",
    "            \n",
    "            # check if it was annotated before\n",
    "            res = check_seen_before(sample, annotations)\n",
    "            if res != None:\n",
    "                sample['annotation'] = res[0]\n",
    "                sample['method'] = res[1]\n",
    "                annotations[idx] = sample\n",
    "            else:\n",
    "                try:\n",
    "                    res = process_sample(idx, sample, manual, detokenize)\n",
    "                except:\n",
    "                    logger.error(idx)\n",
    "                if res == -1:\n",
    "                    return -1\n",
    "    # save all annotations after finished\n",
    "    with open(checkpoint, \"w+\") as f:\n",
    "        json.dump(annotations, f, indent=2, ensure_ascii=False)  # encode dict into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "80f02d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to start from the beginning - not from a checkpoint (you will lose the prev checkpoint tho)\n",
    "annotations = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1d437a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  16390\n",
      "Source sentence:  In einem Wirtschaftssystem der Reinvestition, was geschieht, wenn wir unsere Handelvorteile verwenden und alle Überschüsse wiederinvestieren, damit wir mehr Äpfel und Birnen herstellen können, als wir zu Beginn hatten?\n",
      "Reference:  In an economy with reinvestment, what happens if we can take our advantages of trade and reinvest any excess so that we can create more apples and pears than we had to start with?\n",
      "Good Translation:  In an economic system of reinvestment, what if we use our trading advantages and reinvest any surpluses so we can produce more fruit than we started with?\n",
      "Incorrect Translation:  In an economic system of reinvestment, what if we use our trading advantages and reinvest any surpluses so we can produce more bananas and oranges than we started with?\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [22], 'character_span': (127, 132), 'token': 'fruit'}, 'in_bad': {'token_index': [22, 23, 24], 'character_span': (127, 146), 'token': 'bananas and oranges'}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▉                                                                            | 1/40 [00:08<05:12,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  16392\n",
      "Source sentence:  Sie müssen durch zahlreiche Luftdruckkammern, eh, Fahrten gehen, ehe sie überhaupt U2's fliegen oder mit Druckanzug fliegen.\n",
      "Reference:  They have to go through a number of altitude chambers, uh, rides before they start even flying U2's or flying with pressure suits.\n",
      "Good Translation:  They have to go through numerous air pressure chambers, eh, rides before they even fly spy planes or fly in a pressure suit.\n",
      "Incorrect Translation:  They have to go through numerous air pressure chambers, eh, rides before they even fly SR-71's or fly in a pressure suit.\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [15, 16], 'character_span': (87, 97), 'token': 'spy planes'}, 'in_bad': {'token_index': [15], 'character_span': (87, 94), 'token': \"SR-71's\"}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████▊                                                                        | 3/40 [00:22<04:38,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  16401\n",
      "Source sentence:  Sie haben gewährt, ich habe gesagt, das Engagement des Königs zu diesem Mann. Sein Ton verriet die Bitterkeit seines Grolls. Ich bin sicher, du hast diesem Mann nicht die Genehmigung des Königs erteilt, sagte er fröhlich.\n",
      "Reference:  You have granted, I am told, the King's commission to this man. His very tone betrayed the bitterness of his rancour. I'm sure you didn't grant the King's commission to this man, he said cheerfully.\n",
      "Good Translation:  You have granted, I have said, the monarch’s commitment to this man. His tone betrayed the bitterness of his resentment. I'm sure you didn't give this man the monarch's approval, he said cheerfully.\n",
      "Incorrect Translation:  You have granted, I have said, the Queen’s commitment to this man. His tone betrayed the bitterness of his resentment. I'm sure you didn't give this man the Queen's approval, he said cheerfully.\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [7], 'character_span': (35, 44), 'token': 'monarch’s'}, 'in_bad': {'token_index': [7], 'character_span': (35, 42), 'token': 'Queen’s'}}, {'in_good': {'token_index': [28], 'character_span': (159, 168), 'token': \"monarch's\"}, 'in_bad': {'token_index': [28], 'character_span': (157, 164), 'token': \"Queen's\"}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████                                                      | 12/40 [01:05<02:27,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  16404\n",
      "Source sentence:  Es gibt einen Ausschlag, der mit einigen Geschlechtskrankheiten einhergeht.\n",
      "Reference:  There is a rash that comes along with some STIs.\n",
      "Good Translation:  There is a rash that is associated with some infections.\n",
      "Incorrect Translation:  There is a rash that is associated with some prion diseases.\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [9], 'character_span': (45, 55), 'token': 'infections'}, 'in_bad': {'token_index': [9, 10], 'character_span': (45, 59), 'token': 'prion diseases'}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████████████████▉                                                | 15/40 [01:35<02:45,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  16407\n",
      "Source sentence:  Ich möchte wissen, sind sie oft in England?\n",
      "Reference:  I want to know, are they often in England?\n",
      "Good Translation:  I want to know, are you often in the UK?\n",
      "Incorrect Translation:  I want to know, are you often in Scotland?\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [8, 9], 'character_span': (33, 39), 'token': 'the UK'}, 'in_bad': {'token_index': [8], 'character_span': (33, 41), 'token': 'Scotland'}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████████████████████▋                                          | 18/40 [01:39<01:52,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  24599\n",
      "Source sentence:  In an economy with reinvestment, what happens if we can take our advantages of trade and reinvest any excess so that we can create more apples and pears than we had to start with?\n",
      "Reference:  In einem Wirtschaftssystem der Reinvestition, was geschieht, wenn wir unsere Handelvorteile verwenden und alle Überschüsse wiederinvestieren, damit wir mehr Äpfel und Birnen herstellen können, als wir zu Beginn hatten?\n",
      "Good Translation:  Was wäre, wenn wir in einem Wirtschaftssystem der Reinvestition unsere Handelsvorteile nutzen und alle Überschüsse reinvestieren, damit wir mehr Früchte produzieren können, als wir begonnen haben?\n",
      "Incorrect Translation:  Was wäre, wenn wir in einem Wirtschaftssystem der Reinvestition unsere Handelsvorteile nutzen und alle Überschüsse reinvestieren, damit wir mehr Bananen und Orangen produzieren können, als wir begonnen haben?\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [19], 'character_span': (145, 152), 'token': 'Früchte'}, 'in_bad': {'token_index': [19, 20, 21], 'character_span': (145, 164), 'token': 'Bananen und Orangen'}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▏                              | 24/40 [01:49<00:56,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  24600\n",
      "Source sentence:  You have granted, I am told, the King's commission to this man. His very tone betrayed the bitterness of his rancour. I'm sure you didn't grant the King's commission to this man, he said cheerfully.\n",
      "Reference:  Sie haben gewährt, ich habe gesagt, das Engagement des Königs zu diesem Mann. Sein Ton verriet die Bitterkeit seines Grolls. Ich bin sicher, du hast diesem Mann nicht die Genehmigung des Königs erteilt, sagte er fröhlich.\n",
      "Good Translation:  Sie haben, sagte ich, die Verpflichtung des Monarchen gegenüber diesem Mann gewährt. Sein Ton verriet die Bitterkeit seines Grolls. Ich bin sicher, Sie haben diesem Mann nicht die Zustimmung des Monarchen gegeben, sagte er fröhlich.\n",
      "Incorrect Translation:  Sie haben, sagte ich, die Verpflichtung der Königin gegenüber diesem Mann gewährt. Sein Ton verriet die Bitterkeit seines Grolls. Ich bin sicher, Sie haben diesem Mann nicht die Zustimmung der Königin gegeben, sagte er fröhlich.\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [6, 7], 'character_span': (40, 53), 'token': 'des Monarchen'}, 'in_bad': {'token_index': [6, 7], 'character_span': (40, 51), 'token': 'der Königin'}}, {'in_good': {'token_index': [29, 30], 'character_span': (191, 204), 'token': 'des Monarchen'}, 'in_bad': {'token_index': [29, 30], 'character_span': (189, 200), 'token': 'der Königin'}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|████████████████████████████████████████████████▏                            | 25/40 [01:58<01:01,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  24603\n",
      "Source sentence:  and we keep our cans in one thing and glass in another and paper in another it once it gets full getting it loaded into the car and taking it is a pain. It's hard to load up the paper, glass and can after separating them into their own container.\n",
      "Reference:  und wir trennen unsere Dosen, Glas und Papier und wenn die verschiedenen Behälter voll sind, werden sie ins Auto geladen und wir bringen sie weg, es ist nervig. Es ist schwierig, das Papier, Glas und die Dosen aufzuladen, nachdem man sie in ihre eigenen Behälter getrennt hat.\n",
      "Good Translation:  und wir trennen unsere dosen, glas und papier und wenn die verschiedenen container voll sind, wird es ins fahrzeug geladen und wir nehmen es mit, das ist ärgerlich. Es ist schwierig, das Papier, das Glas und die Dose zu füllen, nachdem sie in ihre eigenen Behälter getrennt wurden.\n",
      "Incorrect Translation:  und wir trennen unsere dosen, glas und papier und wenn die verschiedenen container voll sind, wird es in den lastwagen geladen und wir nehmen es mit, das ist ärgerlich. Es ist schwierig, das Papier, das Glas und die Dose zu füllen, nachdem sie in ihre eigenen Behälter getrennt wurden.\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [17, 18], 'character_span': (102, 114), 'token': 'ins fahrzeug'}, 'in_bad': {'token_index': [17, 18, 19], 'character_span': (102, 118), 'token': 'in den lastwagen'}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▉                       | 28/40 [02:04<00:41,  3.43s/it]WARNING:logger:check this - too long: 24607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  24607\n",
      "Source sentence:  The Republican National Convention in Houston was in August.\n",
      "Reference:  Die republikanische Nationalversammlung in Houston fand im August statt.\n",
      "Good Translation:  Im Sommer fand die Republikanische Nationalversammlung in Houston statt.\n",
      "Incorrect Translation:  Im Juli fand die Republikanische Nationalversammlung in statt.\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [1, 2, 3, 4, 5, 6, 7], 'character_span': (3, 65), 'token': 'Sommer fand die Republikanische Nationalversammlung in Houston'}, 'in_bad': {'token_index': [1, 2, 3, 4, 5, 6], 'character_span': (3, 55), 'token': 'Juli fand die Republikanische Nationalversammlung in'}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:Im <Juli> fand die Republikanische Nationalversammlung in statt.\n",
      "Source sentence:  The Republican National Convention in Houston was in August.\n",
      "Reference:  Die republikanische Nationalversammlung in Houston fand im August statt.\n",
      "Good Translation:  Im Sommer fand die Republikanische Nationalversammlung in Houston statt.\n",
      "Incorrect Translation:  Im Juli fand die Republikanische Nationalversammlung in statt.\n",
      "Enter the incorrect translation with the < and > to show the error spans (exit to stop): \n",
      "Im <Juli> fand die Republikanische Nationalversammlung in statt.\n",
      "Enter the correct/reference translation with the < and > to show the error spans (exit to stop): \n",
      "Im <Sommer> fand die Republikanische Nationalversammlung in <Houston> statt.\n",
      "Annotation:  [{'in_good': None, 'in_bad': {'token_index': None, 'character_span': (3, 7), 'token': 'Juli'}}, {'in_good': {'token_index': None, 'character_span': (3, 9), 'token': 'Sommer'}, 'in_bad': None}, {'in_good': {'token_index': None, 'character_span': (58, 65), 'token': 'Houston'}, 'in_bad': None}]\n",
      "\n",
      " To accept it press enter or to annotate again enter any other string: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████▌               | 32/40 [02:56<00:54,  6.85s/it]WARNING:logger:check this - too long: 24612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> For this sample we compare the Incorrect translation with the Good translation.\n",
      "\n",
      "\n",
      "ID:  24612\n",
      "Source sentence:  There is a rash that comes along with some STIs.\n",
      "Reference:  Es gibt einen Ausschlag, der mit einigen Geschlechtskrankheiten einhergeht.\n",
      "Good Translation:  Es gibt einen Ausschlag, der mit einigen Infektionen verbunden ist.\n",
      "Incorrect Translation:  Es gibt einen Hautausschlag, der mit einigen Prionenerkrankungen in Verbindung gebracht wird.\n",
      "Suggested annotation:\n",
      "[{'in_good': {'token_index': [3, 4, 5, 6, 7, 8, 9], 'character_span': (14, 66), 'token': 'Ausschlag, der mit einigen Infektionen verbunden ist'}, 'in_bad': {'token_index': [3, 4, 5, 6, 7, 8, 9, 10, 11], 'character_span': (14, 92), 'token': 'Hautausschlag, der mit einigen Prionenerkrankungen in Verbindung gebracht wird'}}] \n",
      "\n",
      "To accept the suggested annotation click on enter. To skip this one enter skip. Otherwise enter anything else:d\n",
      "Source sentence:  There is a rash that comes along with some STIs.\n",
      "Reference:  Es gibt einen Ausschlag, der mit einigen Geschlechtskrankheiten einhergeht.\n",
      "Good Translation:  Es gibt einen Ausschlag, der mit einigen Infektionen verbunden ist.\n",
      "Incorrect Translation:  Es gibt einen Hautausschlag, der mit einigen Prionenerkrankungen in Verbindung gebracht wird.\n",
      "Enter the incorrect translation with the < and > to show the error spans (exit to stop): \n",
      "Es gibt einen <Hautausschlag>, der mit einigen <Prionenerkrankungen in Verbindung gebracht wird>.\n",
      "Enter the correct/reference translation with the < and > to show the error spans (exit to stop): \n",
      "Es gibt einen <Ausschlag>, der mit einigen <Infektionen verbunden ist>.\n",
      "Annotation:  [{'in_good': None, 'in_bad': {'token_index': None, 'character_span': (14, 27), 'token': 'Hautausschlag'}}, {'in_good': None, 'in_bad': {'token_index': None, 'character_span': (45, 92), 'token': 'Prionenerkrankungen in Verbindung gebracht wird'}}, {'in_good': {'token_index': None, 'character_span': (14, 23), 'token': 'Ausschlag'}, 'in_bad': None}, {'in_good': {'token_index': None, 'character_span': (41, 66), 'token': 'Infektionen verbunden ist'}, 'in_bad': None}]\n",
      "\n",
      " To accept it press enter or to annotate again enter any other string: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 40/40 [04:08<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# THE ACTUAL PART\n",
    "logger.setLevel(logging.INFO)\n",
    "process_phenomena(samples, manual=True, detokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After this cell there are extra stuff - no need to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1bce7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run normalization over the already annotated samples in coreference-based-on-commonsense\n",
    "# No need to do that for manual annotation!\n",
    "for idx in annotations:\n",
    "    sample = annotations[idx]\n",
    "    good, _, _ = ref_or_good(sample[\"reference\"], sample[\"good-translation\"], sample[\"incorrect-translation\"])\n",
    "    bad = sample['incorrect-translation']\n",
    "    change = sample['annotation']\n",
    "    try:\n",
    "        sample['annotation'] = standardize_annotation(change, good, bad)\n",
    "    except:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5871f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoint, \"w+\") as f:\n",
    "    json.dump(annotations, f, indent=2, ensure_ascii=False)  # encode dict into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b899069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to count the number of samples in any phenomena\n",
    "# No need to do that for manual annotation!\n",
    "count = 0\n",
    "for sample in dataset[\"train\"]:\n",
    "    if sample[\"phenomena\"] in [\"lexical-overlap\", 'xnli-omission-neutral', 'xnli-omission-contradiction', 'xnli-addition-neutral', 'xnli-addition-contradiction']:\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
